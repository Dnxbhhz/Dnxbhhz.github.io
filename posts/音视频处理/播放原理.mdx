---
title: '视频转码解码播放原理'
date: '2025-08-2'
summary: '快速了解视频的基础信息和播放原理'
---

### 视频文件结构

一个视频文件一般是由文件信息和音视频文件组成，视频文件的结构因不同封装格式而不同。视频格式分为封装格式和编码格式，封装格式决定的是视频文件的结构，音视频数据块的大小等，而编码格式决定的是音视频的压缩的方式及算法。前端开发中主要关注的是封装格式，即常见的 `.mp4`、`.webm`、`.ogg`、`.m3u8` 等文件类型。

#### 主流视频封装格式（文件扩展名）

| 格式                     | 全称                       | 是否浏览器原生支持     | 特点与说明                             |
| ------------------------ | -------------------------- | ---------------------- | -------------------------------------- |
| `.mp4`                   | MPEG-4                     | 支持最广泛             | **首选格式**，兼容性好，适合网页播放   |
| `.webm`                  | Web Media                  | Chrome / Firefox 支持  | Google 推出，体积小，适合 Web 用途     |
| `.ogg` / `.ogv`          | Ogg Theora                 | 部分支持（Firefox 好） | 开源格式，支持不如 MP4                 |
| `.m3u8`                  | HLS（HTTP Live Streaming） | 需 `hls.js` 支持       | Apple 开发的**流媒体格式**，可边播边看 |
| `.flv`                   | Flash Video                | 需 `flv.js` 支持       | 老旧格式，适用于直播回放等后端推流系统 |
| `.avi` / `.mov` / `.wmv` | -                          | 不推荐网页播放         | 桌面播放器常见格式，不适合前端网页     |

对于一些流媒体协议，其实也是封装格式，例如 rtmp，rtsp,http-flv 等，后续会详细介绍。

文件信息会记录当前视频文件的一些信息，以便后续对音视频进行解压缩，而音视频数据是压缩过后的数据，数据经过压缩后，是一块一块的，一般情况下，根据时间顺序，音频数据和视频数据会交叉存储，但是每一小块音频数据或视频数据并不一定是独立的一帧，压缩后的音视频数据块，只是编码器根据压缩算法切分的数据单元，**可能并不对应或代表某一个完整的音/视频帧**，而是要解码器将多个块组合后，才能还原出完整的一帧画面或声音。

> 音视频文件有轨道的概念，原则上，音频视频轨道可以是多个的，但一般的播放器只会播放一个视频轨道和一个音频轨道，除了音频视频轨道，还可以有其他类型的轨道，轨道其实就是数据块中的 index 标记，存放时还是一块一块的

### 视频帧

视频帧（Frame）就是一幅**静态的图像**。视频就是由一帧帧图像按顺序、快速地显示出来，形成“连续动态”的视觉效果。一个常见的视频可能是 30 帧每秒（FPS）。

#### 视频帧的分类

视频帧并不都是“完整图像”，很多时候是**压缩后的差值数据**。在压缩格式（如 H.264）中，帧主要分为：

| 帧类型             | 含义                | 特点                     |
| ------------------ | ------------------- | ------------------------ |
| I 帧（关键帧）     | Intra Frame         | 完整图像，可独立解码     |
| P 帧（预测帧）     | Predicted Frame     | 基于前一帧的差值数据     |
| B 帧（双向预测帧） | Bi-predictive Frame | 同时基于前后帧的差值数据 |

举个例子：

| 时间线 | 内容（帧类型）             |
| ------ | -------------------------- |
| 0s     | I 帧（完整）               |
| 0.04s  | P 帧（记录与前一帧的差异） |
| 0.08s  | B 帧（参考前后帧的差异）   |

### 播放工作原理

播放视频文件时，需要按顺序读取视频文件的一块块音视频数据，这个步骤叫做解封装（demux）,读出这些数据后并不能立即播放，因为这些数据是压缩过后的，所以还需要还原成能显示的图像或者音频采样才能播放，这个解压缩的步骤叫做解码（decode）,解码过程根据不同的编码格式不同而不同，但一般编码格式都有对应的解码器程序。

#### 常见视频编码格式（压缩算法）

| 编码          | 名称                                 | 特点                             |
| ------------- | ------------------------------------ | -------------------------------- |
| `H.264`       | AVC（Advanced Video Coding）         | 最常见、兼容性最佳、支持硬解码   |
| `H.265`       | HEVC（High Efficiency Video Coding） | 新一代压缩率高，但浏览器支持有限 |
| `VP8` / `VP9` | Google 开源                          | 用于 `.webm` 格式，压缩率高      |
| `AV1`         | 新一代开源高压缩率编码               | Chrome / Firefox 支持，未来趋势  |

> 浏览器能播放一部分 mp4 文件，是因为浏览器的音视频解码器是内嵌的，只能解压缩几种固定的编码格式，
> 补充说明：每一帧图像，音频采样本身也有自己的格式，图像会有 YUV，RGB 等格式，音频采样会有 float 等样本格式，但一般这些格式处理过程在音视频处理中是不需要特别关心的，因为编码解码时会自动处理这些。

#### 前端播放建议格式

| 场景         | 推荐格式           | 说明                    |
| ------------ | ------------------ | ----------------------- |
| 网页嵌入播放 | `.mp4` + H.264     | 浏览器通用，兼容性最佳  |
| 移动端适配   | `.mp4` / `.webm`   | webm 体积小，适合低带宽 |
| 流媒体直播   | `.m3u8` + `hls.js` | 可播放 HLS 流视频       |
| 后台录播     | `.mp4`             | 可下载，可存档          |

### 音视频同步

音视频根据时间戳来同步，在视频文件的每一小块音视频数据中，一般都含有解码时间戳（DTS，一般决定视频文件的数据块排列顺序）,播放时间戳（PTS，在经过解码解压缩后，每一帧数据都会含有），播放器程序需要根据这个播放时间戳 PTS 切换图像或音频采样，这些时间戳是相对事件，不一定都是从 0 开始，时间戳需要根据时间基换算才能得到具体时间，时间基可以理解为把一秒分成多少份。

> ### 假设：
>
> - 某帧的 PTS = 180000
> - 时间基 time_base = 1 / 90000
>
> 那么：
>
> ```
> 该帧播放时间 = PTS × time_base = 180000 × (1/90000) = 2 秒
> ```
>
> 播放器就知道：
> → 这帧应该在播放第 2 秒时出现！

DTS 和 PTS 不一定是相等的，如 H254 的 B 帧需要滞后解码，DTS 会大于 PTS

### 转码过程工作原理

视频文件，直播流转码成高清流程的过程其实就是在解封装，解码后，对每一帧图像，音频采样进行处理，如改变分辨率，采样率等，之后再重新编码，重新封装就可以了。

如果仅仅是想把视频文件从 mp4 变成 flv 文件，而不改变视频分辨率，编码格式的话，可以解封装后直接重新封装。直播流转码播放也是一样的，只不过封装的格式不一样，但是它们的编码可以同为一样的。
